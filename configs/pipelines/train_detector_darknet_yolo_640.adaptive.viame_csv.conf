
#  Groundtruth file extensions (txt, kw18, etc...). Note: this is indepedent of
#  the format that's stored in the file.
groundtruth_extensions = .csv

#  Algorithm to use for 'groundtruth_reader'.
#  Must be one of the following options:
#  	- habcam :: Reads habcam detection/ground truth files.
#  	- kw18 :: Detected object set reader using kw18 format.
groundtruth_reader:type = viame_csv

#  Can be either: "one_per_file" or "one_per_folder".
groundtruth_style = one_per_folder

#  Semicolon list of seperated image extensions to use in training, images
#  without this extension will not be included.
image_extensions = .jpg;.jpeg;.JPG;.JPEG;.tif;.tiff;.TIF;.TIFF;.png;.PNG;.sgi;.SGI;.bmp;.BMP;.pgm;.PGM

#  Semicolon list of seperated video extensions to use in training, videos
#  without this extension will not be included.
video_extensions = .mp4;.MP4;.mpg;.MPG;.mpeg;.MPEG;.avi;.AVI;.wmv;.WMV;.mov;.MOV;.webm;.WEBM;.ogg;.OGG

#  Pipeline to use to extract video frames if inputs are videos
relativepath video_extractor = filter_default.pipe

#  Percent [0.0, 1.0] of test samples to use if no manual files specified.
default_percent_test = 0.10

#  Number of test frames to group together in one test burst
test_burst_frame_count = 10


detector_trainer:type = ocv_windowed

block detector_trainer:ocv_windowed

  # Directory for all files used in training
  train_directory = augmented_cache

  # Windowing mode, can be disabled, maintain_ar, scale, chip, adaptive
  mode = original_and_resized

  # Resized chip width.
  chip_width = 640

  # Resized chip height.
  chip_height = 640

  # Adaptive size threshold for chipping
  chip_adaptive_thresh = 1600000

  # Don't train on chips with detections smaller than this
  min_train_box_length = 5

  # Uncomment to remove small detections instead of training on them
  #small_box_area = 290
  #small_action = remove

  # Image reader type
  image_reader:type = vxl

endblock

block detector_trainer:ocv_windowed:trainer

  type = darknet

  #  GPU index. Only used when darknet is compiled with GPU support.
  darknet:gpu_index = 0

  #  Type of network
  darknet:model_type = yolov4

  #  Name of network config file.
  relativepath darknet:net_config = models/yolo_train.cfg

  #  Seed weights file.
  relativepath darknet:seed_weights = models/yolo_seed.wt

  #  Pipeline template file.
  relativepath darknet:pipeline_template = templates/embedded_yolo.pipe

  # Image reader parameters
  darknet:image_reader:type = vxl
  darknet:image_reader:vxl:force_byte = true

  #  Directory for all files used in training and output models.
  darknet:train_directory = deep_training

  #  Output directory.
  darknet:output_directory = category_models

  #  Only chips with valid groundtruth objects on them will be included in
  #  training.
  darknet:chips_w_gt_only = false

  #  Maximum negative frame ratio
  darknet:max_neg_ratio = 1

  #  Pre-processing resize option, can be: disabled, maintain_ar, scale, chip, or
  #  chip_and_original.
  darknet:resize_option = disabled

  #  Image scaling factor used when resize_option is scale or chip.
  darknet:scale = 1.0

  #  Width resolution for darknet base layer.
  darknet:resize_width = 640

  #  Height resolution for darknet base layer.
  darknet:resize_height = 640

  #  Batch size to use during training
  darknet:batch_size = 64

  #  Batch subdivisions to use during training
  darknet:batch_subdivisions = 32

  #  Percentage of which a target must appear on a chip for it to be included as a
  #  training sample for said chip.
  darknet:overlap_required = 0.05

  #  Random intensity shift chip augmentation [0.0,1.0] - 0.0 is turned off.
  darknet:random_int_shift = 0.60

  #  Skip file formatting, assume that the train_directory is pre-populated with
  #  all files required for model training.
  darknet:skip_format = false

endblock
